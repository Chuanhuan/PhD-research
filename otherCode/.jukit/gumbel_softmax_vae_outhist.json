{"8VCOGkPWM3": [{"output_type": "stream", "name": "stdout", "text": "Epoch: 0, Batch: 0, Loss: 552.1789, Temp: 0.9990\nEpoch: 0, Batch: 100, Loss: 174.6073, Temp: 0.9039\nEpoch: 0, Batch: 200, Loss: 158.5381, Temp: 0.8178\nEpoch: 0, Batch: 300, Loss: 142.9841, Temp: 0.7400\nEpoch: 0, Batch: 400, Loss: 148.5416, Temp: 0.6695\nEpoch: 0, Batch: 500, Loss: 147.5821, Temp: 0.6058\nEpoch: 0, Batch: 600, Loss: 138.2737, Temp: 0.5481\nEpoch: 0, Batch: 700, Loss: 129.0952, Temp: 0.5000\nEpoch: 0, Batch: 800, Loss: 127.4516, Temp: 0.5000\nEpoch: 0, Batch: 900, Loss: 124.1709, Temp: 0.5000\nEpoch: 1, Batch: 0, Loss: 121.2123, Temp: 0.5000\nEpoch: 1, Batch: 100, Loss: 116.0710, Temp: 0.5000\nEpoch: 1, Batch: 200, Loss: 120.7133, Temp: 0.5000\nEpoch: 1, Batch: 300, Loss: 121.2611, Temp: 0.5000\nEpoch: 1, Batch: 400, Loss: 117.3905, Temp: 0.5000\nEpoch: 1, Batch: 500, Loss: 113.2472, Temp: 0.5000\nEpoch: 1, Batch: 600, Loss: 121.7946, Temp: 0.5000\nEpoch: 1, Batch: 700, Loss: 118.6514, Temp: 0.5000\nEpoch: 1, Batch: 800, Loss: 118.6433, Temp: 0.5000\nEpoch: 1, Batch: 900, Loss: 118.0127, Temp: 0.5000\nEpoch: 2, Batch: 0, Loss: 118.0595, Temp: 0.5000\nEpoch: 2, Batch: 100, Loss: 115.3845, Temp: 0.5000\nEpoch: 2, Batch: 200, Loss: 110.8133, Temp: 0.5000\nEpoch: 2, Batch: 300, Loss: 114.2950, Temp: 0.5000\nEpoch: 2, Batch: 400, Loss: 114.2367, Temp: 0.5000\nEpoch: 2, Batch: 500, Loss: 112.2467, Temp: 0.5000\nEpoch: 2, Batch: 600, Loss: 104.0193, Temp: 0.5000\nEpoch: 2, Batch: 700, Loss: 108.2825, Temp: 0.5000\nEpoch: 2, Batch: 800, Loss: 110.6386, Temp: 0.5000\nEpoch: 2, Batch: 900, Loss: 105.9493, Temp: 0.5000\nEpoch: 3, Batch: 0, Loss: 114.2630, Temp: 0.5000\nEpoch: 3, Batch: 100, Loss: 110.6929, Temp: 0.5000\nEpoch: 3, Batch: 200, Loss: 110.6678, Temp: 0.5000\nEpoch: 3, Batch: 300, Loss: 110.3404, Temp: 0.5000\nEpoch: 3, Batch: 400, Loss: 110.4647, Temp: 0.5000\nEpoch: 3, Batch: 500, Loss: 114.7912, Temp: 0.5000\nEpoch: 3, Batch: 600, Loss: 105.1468, Temp: 0.5000\nEpoch: 3, Batch: 700, Loss: 108.1586, Temp: 0.5000\nEpoch: 3, Batch: 800, Loss: 105.7718, Temp: 0.5000\nEpoch: 3, Batch: 900, Loss: 103.2085, Temp: 0.5000\nEpoch: 4, Batch: 0, Loss: 106.6338, Temp: 0.5000\nEpoch: 4, Batch: 100, Loss: 109.6719, Temp: 0.5000\nEpoch: 4, Batch: 200, Loss: 113.6921, Temp: 0.5000\nEpoch: 4, Batch: 300, Loss: 110.6179, Temp: 0.5000\nEpoch: 4, Batch: 400, Loss: 108.7086, Temp: 0.5000\nEpoch: 4, Batch: 500, Loss: 104.4566, Temp: 0.5000\nEpoch: 4, Batch: 600, Loss: 112.9521, Temp: 0.5000\nEpoch: 4, Batch: 700, Loss: 101.3345, Temp: 0.5000\nEpoch: 4, Batch: 800, Loss: 107.6642, Temp: 0.5000\nEpoch: 4, Batch: 900, Loss: 108.3843, Temp: 0.5000\nEpoch: 5, Batch: 0, Loss: 105.4417, Temp: 0.5000\nEpoch: 5, Batch: 100, Loss: 110.0263, Temp: 0.5000\nEpoch: 5, Batch: 200, Loss: 104.9673, Temp: 0.5000\nEpoch: 5, Batch: 300, Loss: 103.7987, Temp: 0.5000\nEpoch: 5, Batch: 400, Loss: 108.0106, Temp: 0.5000\nEpoch: 5, Batch: 500, Loss: 105.4622, Temp: 0.5000\nEpoch: 5, Batch: 600, Loss: 102.6579, Temp: 0.5000\nEpoch: 5, Batch: 700, Loss: 102.7665, Temp: 0.5000\nEpoch: 5, Batch: 800, Loss: 106.7963, Temp: 0.5000\nEpoch: 5, Batch: 900, Loss: 111.0410, Temp: 0.5000\nEpoch: 6, Batch: 0, Loss: 104.7950, Temp: 0.5000\nEpoch: 6, Batch: 100, Loss: 109.0746, Temp: 0.5000\nEpoch: 6, Batch: 200, Loss: 105.5523, Temp: 0.5000\nEpoch: 6, Batch: 300, Loss: 107.3409, Temp: 0.5000\nEpoch: 6, Batch: 400, Loss: 113.3815, Temp: 0.5000\nEpoch: 6, Batch: 500, Loss: 108.0531, Temp: 0.5000\nEpoch: 6, Batch: 600, Loss: 99.8182, Temp: 0.5000\nEpoch: 6, Batch: 700, Loss: 107.0243, Temp: 0.5000\nEpoch: 6, Batch: 800, Loss: 107.5333, Temp: 0.5000\nEpoch: 6, Batch: 900, Loss: 106.5391, Temp: 0.5000\nEpoch: 7, Batch: 0, Loss: 112.6667, Temp: 0.5000\nEpoch: 7, Batch: 100, Loss: 110.4551, Temp: 0.5000\nEpoch: 7, Batch: 200, Loss: 101.8378, Temp: 0.5000\nEpoch: 7, Batch: 300, Loss: 104.0310, Temp: 0.5000\nEpoch: 7, Batch: 400, Loss: 107.8388, Temp: 0.5000\nEpoch: 7, Batch: 500, Loss: 102.2706, Temp: 0.5000\nEpoch: 7, Batch: 600, Loss: 108.6706, Temp: 0.5000\nEpoch: 7, Batch: 700, Loss: 104.4109, Temp: 0.5000\nEpoch: 7, Batch: 800, Loss: 110.0274, Temp: 0.5000\nEpoch: 7, Batch: 900, Loss: 106.3323, Temp: 0.5000\nEpoch: 8, Batch: 0, Loss: 104.3394, Temp: 0.5000\nEpoch: 8, Batch: 100, Loss: 96.9064, Temp: 0.5000\nEpoch: 8, Batch: 200, Loss: 110.3398, Temp: 0.5000\nEpoch: 8, Batch: 300, Loss: 107.3786, Temp: 0.5000\nEpoch: 8, Batch: 400, Loss: 109.2225, Temp: 0.5000\nEpoch: 8, Batch: 500, Loss: 107.2305, Temp: 0.5000\nEpoch: 8, Batch: 600, Loss: 103.7903, Temp: 0.5000\nEpoch: 8, Batch: 700, Loss: 106.4706, Temp: 0.5000\nEpoch: 8, Batch: 800, Loss: 110.9227, Temp: 0.5000\nEpoch: 8, Batch: 900, Loss: 105.0784, Temp: 0.5000\nEpoch: 9, Batch: 0, Loss: 102.3521, Temp: 0.5000\nEpoch: 9, Batch: 100, Loss: 102.5669, Temp: 0.5000\nEpoch: 9, Batch: 200, Loss: 96.6437, Temp: 0.5000\nEpoch: 9, Batch: 300, Loss: 109.5126, Temp: 0.5000\nEpoch: 9, Batch: 400, Loss: 100.7905, Temp: 0.5000\nEpoch: 9, Batch: 500, Loss: 104.5613, Temp: 0.5000\nEpoch: 9, Batch: 600, Loss: 102.9127, Temp: 0.5000\nEpoch: 9, Batch: 700, Loss: 106.7842, Temp: 0.5000\nEpoch: 9, Batch: 800, Loss: 109.6624, Temp: 0.5000\nEpoch: 9, Batch: 900, Loss: 101.6986, Temp: 0.5000\nEpoch: 10, Batch: 0, Loss: 102.8041, Temp: 0.5000\nEpoch: 10, Batch: 100, Loss: 105.1149, Temp: 0.5000\nEpoch: 10, Batch: 200, Loss: 102.4752, Temp: 0.5000\nEpoch: 10, Batch: 300, Loss: 111.0760, Temp: 0.5000\nEpoch: 10, Batch: 400, Loss: 104.5475, Temp: 0.5000\nEpoch: 10, Batch: 500, Loss: 109.4673, Temp: 0.5000\nEpoch: 10, Batch: 600, Loss: 102.5874, Temp: 0.5000\nEpoch: 10, Batch: 700, Loss: 104.1283, Temp: 0.5000\nEpoch: 10, Batch: 800, Loss: 107.7062, Temp: 0.5000\nEpoch: 10, Batch: 900, Loss: 102.9779, Temp: 0.5000\nEpoch: 11, Batch: 0, Loss: 107.1630, Temp: 0.5000\nEpoch: 11, Batch: 100, Loss: 104.1793, Temp: 0.5000\nEpoch: 11, Batch: 200, Loss: 105.8202, Temp: 0.5000\nEpoch: 11, Batch: 300, Loss: 105.3620, Temp: 0.5000\nEpoch: 11, Batch: 400, Loss: 96.3697, Temp: 0.5000\nEpoch: 11, Batch: 500, Loss: 102.6576, Temp: 0.5000\nEpoch: 11, Batch: 600, Loss: 102.6013, Temp: 0.5000\nEpoch: 11, Batch: 700, Loss: 98.7857, Temp: 0.5000\nEpoch: 11, Batch: 800, Loss: 106.5456, Temp: 0.5000\nEpoch: 11, Batch: 900, Loss: 106.0342, Temp: 0.5000\nEpoch: 12, Batch: 0, Loss: 105.0391, Temp: 0.5000\nEpoch: 12, Batch: 100, Loss: 101.8582, Temp: 0.5000\nEpoch: 12, Batch: 200, Loss: 104.5635, Temp: 0.5000\nEpoch: 12, Batch: 300, Loss: 104.0276, Temp: 0.5000\nEpoch: 12, Batch: 400, Loss: 104.5851, Temp: 0.5000\nEpoch: 12, Batch: 500, Loss: 101.2643, Temp: 0.5000\nEpoch: 12, Batch: 600, Loss: 102.8384, Temp: 0.5000\nEpoch: 12, Batch: 700, Loss: 104.7252, Temp: 0.5000\nEpoch: 12, Batch: 800, Loss: 103.6496, Temp: 0.5000\nEpoch: 12, Batch: 900, Loss: 102.2051, Temp: 0.5000\nEpoch: 13, Batch: 0, Loss: 105.1305, Temp: 0.5000\nEpoch: 13, Batch: 100, Loss: 98.8135, Temp: 0.5000\nEpoch: 13, Batch: 200, Loss: 105.1235, Temp: 0.5000\nEpoch: 13, Batch: 300, Loss: 103.8074, Temp: 0.5000\nEpoch: 13, Batch: 400, Loss: 100.9492, Temp: 0.5000\nEpoch: 13, Batch: 500, Loss: 104.6175, Temp: 0.5000\nEpoch: 13, Batch: 600, Loss: 104.1559, Temp: 0.5000\nEpoch: 13, Batch: 700, Loss: 105.2411, Temp: 0.5000\nEpoch: 13, Batch: 800, Loss: 104.9921, Temp: 0.5000\nEpoch: 13, Batch: 900, Loss: 104.2278, Temp: 0.5000\nEpoch: 14, Batch: 0, Loss: 104.3815, Temp: 0.5000\nEpoch: 14, Batch: 100, Loss: 95.7703, Temp: 0.5000\nEpoch: 14, Batch: 200, Loss: 108.0092, Temp: 0.5000\nEpoch: 14, Batch: 300, Loss: 108.1821, Temp: 0.5000\nEpoch: 14, Batch: 400, Loss: 99.8935, Temp: 0.5000\nEpoch: 14, Batch: 500, Loss: 102.6432, Temp: 0.5000\nEpoch: 14, Batch: 600, Loss: 104.1628, Temp: 0.5000\nEpoch: 14, Batch: 700, Loss: 105.6294, Temp: 0.5000\nEpoch: 14, Batch: 800, Loss: 100.7272, Temp: 0.5000\nEpoch: 14, Batch: 900, Loss: 103.2704, Temp: 0.5000\nEpoch: 15, Batch: 0, Loss: 104.7158, Temp: 0.5000\nEpoch: 15, Batch: 100, Loss: 102.5262, Temp: 0.5000\nEpoch: 15, Batch: 200, Loss: 100.5642, Temp: 0.5000\nEpoch: 15, Batch: 300, Loss: 103.7129, Temp: 0.5000\nEpoch: 15, Batch: 400, Loss: 103.7176, Temp: 0.5000\nEpoch: 15, Batch: 500, Loss: 102.0238, Temp: 0.5000\nEpoch: 15, Batch: 600, Loss: 100.8195, Temp: 0.5000\nEpoch: 15, Batch: 700, Loss: 102.0635, Temp: 0.5000\nEpoch: 15, Batch: 800, Loss: 101.9173, Temp: 0.5000\nEpoch: 15, Batch: 900, Loss: 107.4754, Temp: 0.5000\nEpoch: 16, Batch: 0, Loss: 102.0359, Temp: 0.5000\nEpoch: 16, Batch: 100, Loss: 106.2958, Temp: 0.5000\nEpoch: 16, Batch: 200, Loss: 105.9136, Temp: 0.5000\nEpoch: 16, Batch: 300, Loss: 109.4102, Temp: 0.5000\nEpoch: 16, Batch: 400, Loss: 110.3719, Temp: 0.5000\nEpoch: 16, Batch: 500, Loss: 101.8165, Temp: 0.5000\nEpoch: 16, Batch: 600, Loss: 102.0301, Temp: 0.5000\nEpoch: 16, Batch: 700, Loss: 106.8366, Temp: 0.5000\nEpoch: 16, Batch: 800, Loss: 105.1170, Temp: 0.5000\nEpoch: 16, Batch: 900, Loss: 101.5743, Temp: 0.5000\nEpoch: 17, Batch: 0, Loss: 98.9272, Temp: 0.5000\nEpoch: 17, Batch: 100, Loss: 106.8217, Temp: 0.5000\nEpoch: 17, Batch: 200, Loss: 101.0595, Temp: 0.5000\nEpoch: 17, Batch: 300, Loss: 104.3838, Temp: 0.5000\nEpoch: 17, Batch: 400, Loss: 101.7355, Temp: 0.5000\nEpoch: 17, Batch: 500, Loss: 104.4098, Temp: 0.5000\nEpoch: 17, Batch: 600, Loss: 105.9913, Temp: 0.5000\nEpoch: 17, Batch: 700, Loss: 104.4472, Temp: 0.5000\nEpoch: 17, Batch: 800, Loss: 102.1504, Temp: 0.5000\nEpoch: 17, Batch: 900, Loss: 100.8293, Temp: 0.5000\nEpoch: 18, Batch: 0, Loss: 99.6597, Temp: 0.5000\nEpoch: 18, Batch: 100, Loss: 100.7072, Temp: 0.5000\nEpoch: 18, Batch: 200, Loss: 102.4230, Temp: 0.5000\nEpoch: 18, Batch: 300, Loss: 105.8762, Temp: 0.5000\nEpoch: 18, Batch: 400, Loss: 102.7357, Temp: 0.5000\nEpoch: 18, Batch: 500, Loss: 104.1953, Temp: 0.5000\nEpoch: 18, Batch: 600, Loss: 103.9309, Temp: 0.5000\nEpoch: 18, Batch: 700, Loss: 104.5777, Temp: 0.5000\nEpoch: 18, Batch: 800, Loss: 101.1775, Temp: 0.5000\nEpoch: 18, Batch: 900, Loss: 103.7899, Temp: 0.5000\nEpoch: 19, Batch: 0, Loss: 103.1811, Temp: 0.5000\nEpoch: 19, Batch: 100, Loss: 105.4180, Temp: 0.5000\nEpoch: 19, Batch: 200, Loss: 100.1800, Temp: 0.5000\nEpoch: 19, Batch: 300, Loss: 99.1677, Temp: 0.5000\nEpoch: 19, Batch: 400, Loss: 98.0945, Temp: 0.5000\nEpoch: 19, Batch: 500, Loss: 105.6009, Temp: 0.5000\nEpoch: 19, Batch: 600, Loss: 102.6186, Temp: 0.5000\nEpoch: 19, Batch: 700, Loss: 108.0398, Temp: 0.5000\nEpoch: 19, Batch: 800, Loss: 103.4779, Temp: 0.5000\nEpoch: 19, Batch: 900, Loss: 100.3882, Temp: 0.5000\nEpoch: 20, Batch: 0, Loss: 100.2888, Temp: 0.5000\nEpoch: 20, Batch: 100, Loss: 102.3141, Temp: 0.5000\nEpoch: 20, Batch: 200, Loss: 106.8131, Temp: 0.5000\nEpoch: 20, Batch: 300, Loss: 102.6967, Temp: 0.5000\nEpoch: 20, Batch: 400, Loss: 101.9216, Temp: 0.5000\nEpoch: 20, Batch: 500, Loss: 104.4516, Temp: 0.5000\nEpoch: 20, Batch: 600, Loss: 102.0851, Temp: 0.5000\nEpoch: 20, Batch: 700, Loss: 110.1369, Temp: 0.5000\nEpoch: 20, Batch: 800, Loss: 99.9727, Temp: 0.5000\nEpoch: 20, Batch: 900, Loss: 102.0778, Temp: 0.5000\nEpoch: 21, Batch: 0, Loss: 106.2372, Temp: 0.5000\nEpoch: 21, Batch: 100, Loss: 108.6483, Temp: 0.5000\nEpoch: 21, Batch: 200, Loss: 97.6697, Temp: 0.5000\nEpoch: 21, Batch: 300, Loss: 104.9296, Temp: 0.5000\nEpoch: 21, Batch: 400, Loss: 102.1100, Temp: 0.5000\nEpoch: 21, Batch: 500, Loss: 104.6842, Temp: 0.5000\nEpoch: 21, Batch: 600, Loss: 103.8692, Temp: 0.5000\nEpoch: 21, Batch: 700, Loss: 101.0487, Temp: 0.5000\nEpoch: 21, Batch: 800, Loss: 96.3145, Temp: 0.5000\nEpoch: 21, Batch: 900, Loss: 102.1732, Temp: 0.5000\nEpoch: 22, Batch: 0, Loss: 103.0270, Temp: 0.5000\nEpoch: 22, Batch: 100, Loss: 106.3610, Temp: 0.5000\nEpoch: 22, Batch: 200, Loss: 94.7983, Temp: 0.5000\nEpoch: 22, Batch: 300, Loss: 102.0725, Temp: 0.5000\nEpoch: 22, Batch: 400, Loss: 105.9981, Temp: 0.5000\nEpoch: 22, Batch: 500, Loss: 109.4913, Temp: 0.5000\nEpoch: 22, Batch: 600, Loss: 106.4385, Temp: 0.5000\nEpoch: 22, Batch: 700, Loss: 107.7840, Temp: 0.5000\nEpoch: 22, Batch: 800, Loss: 112.0180, Temp: 0.5000\nEpoch: 22, Batch: 900, Loss: 97.0521, Temp: 0.5000\nEpoch: 23, Batch: 0, Loss: 99.3959, Temp: 0.5000\nEpoch: 23, Batch: 100, Loss: 103.0474, Temp: 0.5000\nEpoch: 23, Batch: 200, Loss: 105.4390, Temp: 0.5000\nEpoch: 23, Batch: 300, Loss: 105.8222, Temp: 0.5000\nEpoch: 23, Batch: 400, Loss: 103.8711, Temp: 0.5000\nEpoch: 23, Batch: 500, Loss: 101.6032, Temp: 0.5000\nEpoch: 23, Batch: 600, Loss: 101.2648, Temp: 0.5000\nEpoch: 23, Batch: 700, Loss: 104.3908, Temp: 0.5000\nEpoch: 23, Batch: 800, Loss: 109.4013, Temp: 0.5000\nEpoch: 23, Batch: 900, Loss: 110.0822, Temp: 0.5000\nEpoch: 24, Batch: 0, Loss: 106.5535, Temp: 0.5000\nEpoch: 24, Batch: 100, Loss: 104.3257, Temp: 0.5000\nEpoch: 24, Batch: 200, Loss: 103.3544, Temp: 0.5000\nEpoch: 24, Batch: 300, Loss: 109.6225, Temp: 0.5000\nEpoch: 24, Batch: 400, Loss: 104.8073, Temp: 0.5000\nEpoch: 24, Batch: 500, Loss: 109.1490, Temp: 0.5000\nEpoch: 24, Batch: 600, Loss: 103.2258, Temp: 0.5000\nEpoch: 24, Batch: 700, Loss: 97.7055, Temp: 0.5000\nEpoch: 24, Batch: 800, Loss: 101.1053, Temp: 0.5000\nEpoch: 24, Batch: 900, Loss: 100.5840, Temp: 0.5000\nEpoch: 25, Batch: 0, Loss: 100.0325, Temp: 0.5000\nEpoch: 25, Batch: 100, Loss: 106.3764, Temp: 0.5000\nEpoch: 25, Batch: 200, Loss: 107.9551, Temp: 0.5000\nEpoch: 25, Batch: 300, Loss: 102.4341, Temp: 0.5000\nEpoch: 25, Batch: 400, Loss: 102.7895, Temp: 0.5000\nEpoch: 25, Batch: 500, Loss: 102.9320, Temp: 0.5000\nEpoch: 25, Batch: 600, Loss: 96.8002, Temp: 0.5000\nEpoch: 25, Batch: 700, Loss: 102.8615, Temp: 0.5000\nEpoch: 25, Batch: 800, Loss: 103.1249, Temp: 0.5000\nEpoch: 25, Batch: 900, Loss: 105.3889, Temp: 0.5000\nEpoch: 26, Batch: 0, Loss: 99.3975, Temp: 0.5000\nEpoch: 26, Batch: 100, Loss: 103.3868, Temp: 0.5000\nEpoch: 26, Batch: 200, Loss: 103.9195, Temp: 0.5000\nEpoch: 26, Batch: 300, Loss: 105.1538, Temp: 0.5000\nEpoch: 26, Batch: 400, Loss: 100.0153, Temp: 0.5000\nEpoch: 26, Batch: 500, Loss: 99.5744, Temp: 0.5000\nEpoch: 26, Batch: 600, Loss: 99.9205, Temp: 0.5000\nEpoch: 26, Batch: 700, Loss: 107.0270, Temp: 0.5000\nEpoch: 26, Batch: 800, Loss: 106.1885, Temp: 0.5000\nEpoch: 26, Batch: 900, Loss: 101.4395, Temp: 0.5000\nEpoch: 27, Batch: 0, Loss: 102.2259, Temp: 0.5000\nEpoch: 27, Batch: 100, Loss: 109.6606, Temp: 0.5000\nEpoch: 27, Batch: 200, Loss: 102.0769, Temp: 0.5000\nEpoch: 27, Batch: 300, Loss: 106.5266, Temp: 0.5000\nEpoch: 27, Batch: 400, Loss: 102.3204, Temp: 0.5000\nEpoch: 27, Batch: 500, Loss: 99.6573, Temp: 0.5000\nEpoch: 27, Batch: 600, Loss: 105.8515, Temp: 0.5000\nEpoch: 27, Batch: 700, Loss: 100.9066, Temp: 0.5000\nEpoch: 27, Batch: 800, Loss: 100.2841, Temp: 0.5000\nEpoch: 27, Batch: 900, Loss: 108.1808, Temp: 0.5000\nEpoch: 28, Batch: 0, Loss: 103.0721, Temp: 0.5000\nEpoch: 28, Batch: 100, Loss: 101.5251, Temp: 0.5000\nEpoch: 28, Batch: 200, Loss: 99.3097, Temp: 0.5000\nEpoch: 28, Batch: 300, Loss: 94.0568, Temp: 0.5000\nEpoch: 28, Batch: 400, Loss: 106.8821, Temp: 0.5000\nEpoch: 28, Batch: 500, Loss: 100.0876, Temp: 0.5000\nEpoch: 28, Batch: 600, Loss: 109.2307, Temp: 0.5000\nEpoch: 28, Batch: 700, Loss: 100.9605, Temp: 0.5000\nEpoch: 28, Batch: 800, Loss: 102.3147, Temp: 0.5000\nEpoch: 28, Batch: 900, Loss: 104.9705, Temp: 0.5000\nEpoch: 29, Batch: 0, Loss: 104.9515, Temp: 0.5000\nEpoch: 29, Batch: 100, Loss: 105.2052, Temp: 0.5000\nEpoch: 29, Batch: 200, Loss: 99.7586, Temp: 0.5000\nEpoch: 29, Batch: 300, Loss: 101.9863, Temp: 0.5000\nEpoch: 29, Batch: 400, Loss: 101.7225, Temp: 0.5000\nEpoch: 29, Batch: 500, Loss: 107.1010, Temp: 0.5000\nEpoch: 29, Batch: 600, Loss: 100.8955, Temp: 0.5000\nEpoch: 29, Batch: 700, Loss: 106.5580, Temp: 0.5000\nEpoch: 29, Batch: 800, Loss: 99.4152, Temp: 0.5000\nEpoch: 29, Batch: 900, Loss: 103.3898, Temp: 0.5000\nEpoch: 30, Batch: 0, Loss: 102.6490, Temp: 0.5000\nEpoch: 30, Batch: 100, Loss: 100.5290, Temp: 0.5000\nEpoch: 30, Batch: 200, Loss: 99.2645, Temp: 0.5000\nEpoch: 30, Batch: 300, Loss: 103.7706, Temp: 0.5000\nEpoch: 30, Batch: 400, Loss: 100.2207, Temp: 0.5000\nEpoch: 30, Batch: 500, Loss: 99.9352, Temp: 0.5000\nEpoch: 30, Batch: 600, Loss: 100.3514, Temp: 0.5000\nEpoch: 30, Batch: 700, Loss: 105.9550, Temp: 0.5000\nEpoch: 30, Batch: 800, Loss: 102.9432, Temp: 0.5000\nEpoch: 30, Batch: 900, Loss: 101.8103, Temp: 0.5000\nEpoch: 31, Batch: 0, Loss: 101.4299, Temp: 0.5000\nEpoch: 31, Batch: 100, Loss: 103.0944, Temp: 0.5000\nEpoch: 31, Batch: 200, Loss: 102.2872, Temp: 0.5000\nEpoch: 31, Batch: 300, Loss: 99.5031, Temp: 0.5000\nEpoch: 31, Batch: 400, Loss: 102.6046, Temp: 0.5000\nEpoch: 31, Batch: 500, Loss: 111.0247, Temp: 0.5000\nEpoch: 31, Batch: 600, Loss: 97.2512, Temp: 0.5000\nEpoch: 31, Batch: 700, Loss: 101.4988, Temp: 0.5000\nEpoch: 31, Batch: 800, Loss: 100.6435, Temp: 0.5000\nEpoch: 31, Batch: 900, Loss: 105.9773, Temp: 0.5000\nEpoch: 32, Batch: 0, Loss: 100.3245, Temp: 0.5000\nEpoch: 32, Batch: 100, Loss: 102.9117, Temp: 0.5000\nEpoch: 32, Batch: 200, Loss: 100.0567, Temp: 0.5000\nEpoch: 32, Batch: 300, Loss: 103.4720, Temp: 0.5000\nEpoch: 32, Batch: 400, Loss: 109.5480, Temp: 0.5000\nEpoch: 32, Batch: 500, Loss: 101.4066, Temp: 0.5000\nEpoch: 32, Batch: 600, Loss: 98.5068, Temp: 0.5000\nEpoch: 32, Batch: 700, Loss: 99.1862, Temp: 0.5000\nEpoch: 32, Batch: 800, Loss: 99.4684, Temp: 0.5000\nEpoch: 32, Batch: 900, Loss: 107.5928, Temp: 0.5000\nEpoch: 33, Batch: 0, Loss: 102.0661, Temp: 0.5000\nEpoch: 33, Batch: 100, Loss: 101.2849, Temp: 0.5000\nEpoch: 33, Batch: 200, Loss: 107.9637, Temp: 0.5000\nEpoch: 33, Batch: 300, Loss: 104.0017, Temp: 0.5000\nEpoch: 33, Batch: 400, Loss: 97.7165, Temp: 0.5000\nEpoch: 33, Batch: 500, Loss: 98.9492, Temp: 0.5000\nEpoch: 33, Batch: 600, Loss: 104.1895, Temp: 0.5000\nEpoch: 33, Batch: 700, Loss: 100.1532, Temp: 0.5000\nEpoch: 33, Batch: 800, Loss: 100.9346, Temp: 0.5000\nEpoch: 33, Batch: 900, Loss: 103.6602, Temp: 0.5000\nEpoch: 34, Batch: 0, Loss: 95.4451, Temp: 0.5000\nEpoch: 34, Batch: 100, Loss: 101.0068, Temp: 0.5000\nEpoch: 34, Batch: 200, Loss: 105.4789, Temp: 0.5000\nEpoch: 34, Batch: 300, Loss: 100.4380, Temp: 0.5000\nEpoch: 34, Batch: 400, Loss: 103.5220, Temp: 0.5000\nEpoch: 34, Batch: 500, Loss: 101.8368, Temp: 0.5000\nEpoch: 34, Batch: 600, Loss: 104.6913, Temp: 0.5000\nEpoch: 34, Batch: 700, Loss: 105.8329, Temp: 0.5000\nEpoch: 34, Batch: 800, Loss: 110.3720, Temp: 0.5000\nEpoch: 34, Batch: 900, Loss: 102.2572, Temp: 0.5000\nEpoch: 35, Batch: 0, Loss: 93.8247, Temp: 0.5000\nEpoch: 35, Batch: 100, Loss: 98.0925, Temp: 0.5000\nEpoch: 35, Batch: 200, Loss: 102.1817, Temp: 0.5000\nEpoch: 35, Batch: 300, Loss: 105.9667, Temp: 0.5000\nEpoch: 35, Batch: 400, Loss: 101.0183, Temp: 0.5000\nEpoch: 35, Batch: 500, Loss: 101.2245, Temp: 0.5000\nEpoch: 35, Batch: 600, Loss: 98.6268, Temp: 0.5000\nEpoch: 35, Batch: 700, Loss: 104.0280, Temp: 0.5000\nEpoch: 35, Batch: 800, Loss: 99.6317, Temp: 0.5000\nEpoch: 35, Batch: 900, Loss: 101.2468, Temp: 0.5000\nEpoch: 36, Batch: 0, Loss: 101.9191, Temp: 0.5000\nEpoch: 36, Batch: 100, Loss: 100.6829, Temp: 0.5000\nEpoch: 36, Batch: 200, Loss: 99.2805, Temp: 0.5000\nEpoch: 36, Batch: 300, Loss: 101.8267, Temp: 0.5000\nEpoch: 36, Batch: 400, Loss: 101.4801, Temp: 0.5000\nEpoch: 36, Batch: 500, Loss: 104.4612, Temp: 0.5000\nEpoch: 36, Batch: 600, Loss: 102.4178, Temp: 0.5000\nEpoch: 36, Batch: 700, Loss: 97.2930, Temp: 0.5000\nEpoch: 36, Batch: 800, Loss: 95.8494, Temp: 0.5000\nEpoch: 36, Batch: 900, Loss: 100.0932, Temp: 0.5000\nEpoch: 37, Batch: 0, Loss: 93.7912, Temp: 0.5000\nEpoch: 37, Batch: 100, Loss: 106.5606, Temp: 0.5000\nEpoch: 37, Batch: 200, Loss: 101.3255, Temp: 0.5000\nEpoch: 37, Batch: 300, Loss: 103.9524, Temp: 0.5000\nEpoch: 37, Batch: 400, Loss: 103.5749, Temp: 0.5000\nEpoch: 37, Batch: 500, Loss: 104.1251, Temp: 0.5000\nEpoch: 37, Batch: 600, Loss: 99.6027, Temp: 0.5000\nEpoch: 37, Batch: 700, Loss: 104.3493, Temp: 0.5000\nEpoch: 37, Batch: 800, Loss: 99.1113, Temp: 0.5000\nEpoch: 37, Batch: 900, Loss: 104.4350, Temp: 0.5000\nEpoch: 38, Batch: 0, Loss: 103.4544, Temp: 0.5000\nEpoch: 38, Batch: 100, Loss: 103.8708, Temp: 0.5000\nEpoch: 38, Batch: 200, Loss: 106.8712, Temp: 0.5000\nEpoch: 38, Batch: 300, Loss: 101.2286, Temp: 0.5000\nEpoch: 38, Batch: 400, Loss: 104.2123, Temp: 0.5000\nEpoch: 38, Batch: 500, Loss: 103.8612, Temp: 0.5000\nEpoch: 38, Batch: 600, Loss: 98.7274, Temp: 0.5000\nEpoch: 38, Batch: 700, Loss: 103.7666, Temp: 0.5000\nEpoch: 38, Batch: 800, Loss: 100.7933, Temp: 0.5000\nEpoch: 38, Batch: 900, Loss: 102.9168, Temp: 0.5000\nEpoch: 39, Batch: 0, Loss: 97.7523, Temp: 0.5000\nEpoch: 39, Batch: 100, Loss: 100.4653, Temp: 0.5000\nEpoch: 39, Batch: 200, Loss: 101.3051, Temp: 0.5000\nEpoch: 39, Batch: 300, Loss: 98.5207, Temp: 0.5000\nEpoch: 39, Batch: 400, Loss: 99.1339, Temp: 0.5000\nEpoch: 39, Batch: 500, Loss: 101.7790, Temp: 0.5000\nEpoch: 39, Batch: 600, Loss: 98.4645, Temp: 0.5000\nEpoch: 39, Batch: 700, Loss: 97.7211, Temp: 0.5000\nEpoch: 39, Batch: 800, Loss: 102.5995, Temp: 0.5000\nEpoch: 39, Batch: 900, Loss: 103.9610, Temp: 0.5000\nEpoch: 40, Batch: 0, Loss: 100.4206, Temp: 0.5000\nEpoch: 40, Batch: 100, Loss: 98.4267, Temp: 0.5000\nEpoch: 40, Batch: 200, Loss: 100.4416, Temp: 0.5000\nEpoch: 40, Batch: 300, Loss: 105.6292, Temp: 0.5000\nEpoch: 40, Batch: 400, Loss: 97.1093, Temp: 0.5000\nEpoch: 40, Batch: 500, Loss: 98.5397, Temp: 0.5000\nEpoch: 40, Batch: 600, Loss: 103.3257, Temp: 0.5000\nEpoch: 40, Batch: 700, Loss: 98.1245, Temp: 0.5000\nEpoch: 40, Batch: 800, Loss: 100.6757, Temp: 0.5000\nEpoch: 40, Batch: 900, Loss: 104.6048, Temp: 0.5000\nEpoch: 41, Batch: 0, Loss: 104.7770, Temp: 0.5000\nEpoch: 41, Batch: 100, Loss: 106.2511, Temp: 0.5000\nEpoch: 41, Batch: 200, Loss: 102.5907, Temp: 0.5000\nEpoch: 41, Batch: 300, Loss: 103.6606, Temp: 0.5000\nEpoch: 41, Batch: 400, Loss: 99.2078, Temp: 0.5000\nEpoch: 41, Batch: 500, Loss: 106.5907, Temp: 0.5000\nEpoch: 41, Batch: 600, Loss: 103.6963, Temp: 0.5000\nEpoch: 41, Batch: 700, Loss: 98.9112, Temp: 0.5000\nEpoch: 41, Batch: 800, Loss: 101.6907, Temp: 0.5000\nEpoch: 41, Batch: 900, Loss: 106.9176, Temp: 0.5000\nEpoch: 42, Batch: 0, Loss: 103.2695, Temp: 0.5000\nEpoch: 42, Batch: 100, Loss: 96.8929, Temp: 0.5000\nEpoch: 42, Batch: 200, Loss: 102.5331, Temp: 0.5000\nEpoch: 42, Batch: 300, Loss: 103.8008, Temp: 0.5000\nEpoch: 42, Batch: 400, Loss: 100.9895, Temp: 0.5000\nEpoch: 42, Batch: 500, Loss: 101.2458, Temp: 0.5000\nEpoch: 42, Batch: 600, Loss: 104.1256, Temp: 0.5000\nEpoch: 42, Batch: 700, Loss: 98.5350, Temp: 0.5000\nEpoch: 42, Batch: 800, Loss: 104.6101, Temp: 0.5000\nEpoch: 42, Batch: 900, Loss: 102.6448, Temp: 0.5000\nEpoch: 43, Batch: 0, Loss: 97.9996, Temp: 0.5000\nEpoch: 43, Batch: 100, Loss: 102.1647, Temp: 0.5000\nEpoch: 43, Batch: 200, Loss: 100.5389, Temp: 0.5000\nEpoch: 43, Batch: 300, Loss: 108.8891, Temp: 0.5000\nEpoch: 43, Batch: 400, Loss: 99.0910, Temp: 0.5000\nEpoch: 43, Batch: 500, Loss: 99.7636, Temp: 0.5000\nEpoch: 43, Batch: 600, Loss: 98.9171, Temp: 0.5000\nEpoch: 43, Batch: 700, Loss: 105.5877, Temp: 0.5000\nEpoch: 43, Batch: 800, Loss: 96.4511, Temp: 0.5000\nEpoch: 43, Batch: 900, Loss: 106.6746, Temp: 0.5000\nEpoch: 44, Batch: 0, Loss: 99.2546, Temp: 0.5000\nEpoch: 44, Batch: 100, Loss: 103.1678, Temp: 0.5000\nEpoch: 44, Batch: 200, Loss: 104.7242, Temp: 0.5000\nEpoch: 44, Batch: 300, Loss: 105.4694, Temp: 0.5000\nEpoch: 44, Batch: 400, Loss: 102.0728, Temp: 0.5000\nEpoch: 44, Batch: 500, Loss: 97.4093, Temp: 0.5000\nEpoch: 44, Batch: 600, Loss: 94.3694, Temp: 0.5000\nEpoch: 44, Batch: 700, Loss: 104.6896, Temp: 0.5000\nEpoch: 44, Batch: 800, Loss: 105.4849, Temp: 0.5000\nEpoch: 44, Batch: 900, Loss: 100.8887, Temp: 0.5000\nEpoch: 45, Batch: 0, Loss: 102.7660, Temp: 0.5000\nEpoch: 45, Batch: 100, Loss: 97.6142, Temp: 0.5000\nEpoch: 45, Batch: 200, Loss: 103.9195, Temp: 0.5000\nEpoch: 45, Batch: 300, Loss: 102.9288, Temp: 0.5000\nEpoch: 45, Batch: 400, Loss: 99.9864, Temp: 0.5000\nEpoch: 45, Batch: 500, Loss: 104.1383, Temp: 0.5000\nEpoch: 45, Batch: 600, Loss: 105.1613, Temp: 0.5000\nEpoch: 45, Batch: 700, Loss: 99.5646, Temp: 0.5000\nEpoch: 45, Batch: 800, Loss: 101.5090, Temp: 0.5000\nEpoch: 45, Batch: 900, Loss: 102.2904, Temp: 0.5000\nEpoch: 46, Batch: 0, Loss: 100.7319, Temp: 0.5000\nEpoch: 46, Batch: 100, Loss: 103.2327, Temp: 0.5000\nEpoch: 46, Batch: 200, Loss: 104.4540, Temp: 0.5000\nEpoch: 46, Batch: 300, Loss: 97.8854, Temp: 0.5000\nEpoch: 46, Batch: 400, Loss: 100.8421, Temp: 0.5000\nEpoch: 46, Batch: 500, Loss: 106.5212, Temp: 0.5000\nEpoch: 46, Batch: 600, Loss: 101.4866, Temp: 0.5000\nEpoch: 46, Batch: 700, Loss: 100.4354, Temp: 0.5000\nEpoch: 46, Batch: 800, Loss: 99.7650, Temp: 0.5000\nEpoch: 46, Batch: 900, Loss: 98.7711, Temp: 0.5000\nEpoch: 47, Batch: 0, Loss: 97.0953, Temp: 0.5000\nEpoch: 47, Batch: 100, Loss: 95.4007, Temp: 0.5000\nEpoch: 47, Batch: 200, Loss: 105.3536, Temp: 0.5000\nEpoch: 47, Batch: 300, Loss: 97.6700, Temp: 0.5000\nEpoch: 47, Batch: 400, Loss: 97.1892, Temp: 0.5000\nEpoch: 47, Batch: 500, Loss: 104.1505, Temp: 0.5000\nEpoch: 47, Batch: 600, Loss: 106.2224, Temp: 0.5000\nEpoch: 47, Batch: 700, Loss: 95.6319, Temp: 0.5000\nEpoch: 47, Batch: 800, Loss: 96.7509, Temp: 0.5000\nEpoch: 47, Batch: 900, Loss: 102.5468, Temp: 0.5000\nEpoch: 48, Batch: 0, Loss: 99.2827, Temp: 0.5000\nEpoch: 48, Batch: 100, Loss: 99.5668, Temp: 0.5000\nEpoch: 48, Batch: 200, Loss: 98.9477, Temp: 0.5000\nEpoch: 48, Batch: 300, Loss: 103.8027, Temp: 0.5000\nEpoch: 48, Batch: 400, Loss: 97.5629, Temp: 0.5000\nEpoch: 48, Batch: 500, Loss: 102.3414, Temp: 0.5000\nEpoch: 48, Batch: 600, Loss: 105.4255, Temp: 0.5000\nEpoch: 48, Batch: 700, Loss: 100.1828, Temp: 0.5000\nEpoch: 48, Batch: 800, Loss: 104.6991, Temp: 0.5000\nEpoch: 48, Batch: 900, Loss: 103.7074, Temp: 0.5000\nEpoch: 49, Batch: 0, Loss: 98.4658, Temp: 0.5000\nEpoch: 49, Batch: 100, Loss: 99.9959, Temp: 0.5000\nEpoch: 49, Batch: 200, Loss: 103.3479, Temp: 0.5000\nEpoch: 49, Batch: 300, Loss: 100.1903, Temp: 0.5000\nEpoch: 49, Batch: 400, Loss: 104.0395, Temp: 0.5000\nEpoch: 49, Batch: 500, Loss: 98.8700, Temp: 0.5000\nEpoch: 49, Batch: 600, Loss: 102.3830, Temp: 0.5000\nEpoch: 49, Batch: 700, Loss: 97.4183, Temp: 0.5000\nEpoch: 49, Batch: 800, Loss: 102.9356, Temp: 0.5000\nEpoch: 49, Batch: 900, Loss: 99.0252, Temp: 0.5000\n"}], "g20WPwZiEM": [], "LZghsDIrvI": []}