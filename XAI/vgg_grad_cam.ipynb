{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7195e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torchvision.models import vgg19, densenet201\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f737c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# use the ImageNet transformation\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# dataset = datasets.ImageFolder(\n",
    "#     root=os.path.expanduser(\"~/Documents/imagenet_images/elephant/\"),\n",
    "#     transform=transform,\n",
    "# )\n",
    "# # define a 1 image dataset\n",
    "# dataset = datasets.ImageFolder(\n",
    "#     root=\"~/Documents/imagenet_images/elephant/\",\n",
    "#     transform=transform,\n",
    "# )\n",
    "#\n",
    "# # define the dataloader to load that single image\n",
    "# dataloader = data.DataLoader(dataset=dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035100c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "\n",
    "        # get the pretrained VGG19 network\n",
    "        self.vgg = vgg19(weights=True)\n",
    "\n",
    "        # disect the network to access its last convolutional layer\n",
    "        self.features_conv = self.vgg.features[:36]\n",
    "\n",
    "        # get the max pool of the features stem\n",
    "        self.max_pool = nn.MaxPool2d(\n",
    "            kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False\n",
    "        )\n",
    "\n",
    "        # get the classifier of the vgg19\n",
    "        self.classifier = self.vgg.classifier\n",
    "\n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "\n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features_conv(x)\n",
    "\n",
    "        # register the hook\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "\n",
    "        # apply the remaining pooling\n",
    "        x = self.max_pool(x)\n",
    "        x = x.view((1, -1))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    # method for the gradient extraction\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "\n",
    "    # method for the activation exctraction\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeec595",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# initialize the VGG model\n",
    "vgg = VGG()\n",
    "\n",
    "# set the evaluation mode\n",
    "vgg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941dd887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the image from the dataloader\n",
    "# img, _ = next(iter(dataloader))\n",
    "\n",
    "image_dir = os.path.expanduser(\"~/Documents/imagenet_images/piggery/\")\n",
    "image_files = [\n",
    "    os.path.join(image_dir, file)\n",
    "    for file in os.listdir(image_dir)\n",
    "    if file.endswith(\".jpg\")\n",
    "]\n",
    "\n",
    "# Load the ImageNet class names\n",
    "with open(\"./imagenet-classes.txt\") as f:\n",
    "    class_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "image_file = image_files[2]\n",
    "img = Image.open(image_file)\n",
    "img = transform(img).unsqueeze(0)\n",
    "\n",
    "# get the most likely prediction of the model\n",
    "pred_index = vgg(img).argmax(dim=1)\n",
    "\n",
    "print(f\"Prediction: {pred_index}, {class_names[pred_index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b566fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the gradient of the output with respect to the parameters of the model\n",
    "pred = vgg(img)\n",
    "pred[:, pred_index].backward()\n",
    "\n",
    "# pull the gradients out of the model\n",
    "gradients = vgg.get_activations_gradient()\n",
    "print(gradients.shape)\n",
    "\n",
    "# pool the gradients across the channels\n",
    "pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "print(pooled_gradients.shape)\n",
    "\n",
    "# get the activations of the last convolutional layer\n",
    "activations = vgg.get_activations(img).detach()\n",
    "\n",
    "# weight the channels by corresponding gradients\n",
    "for i in range(512):\n",
    "    activations[:, i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "# average the channels of the activations\n",
    "heatmap = torch.mean(activations, dim=1).squeeze()\n",
    "\n",
    "# relu on top of the heatmap\n",
    "# expression (2) in https://arxiv.org/pdf/1610.02391.pdf\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "\n",
    "# normalize the heatmap\n",
    "heatmap /= torch.max(heatmap)\n",
    "\n",
    "# draw the heatmap\n",
    "plt.matshow(heatmap.squeeze())\n",
    "plt.savefig(\"./grad-cam-heatmap.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9409ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Get the base name of the image file (i.e., the name without the directory path)\n",
    "image_name_with_ext = os.path.basename(image_file)\n",
    "\n",
    "# Split the base name into name and extension\n",
    "image_name, image_ext = os.path.splitext(image_name_with_ext)\n",
    "# img = cv2.imread(\"./data/Elephant/data/05fig34.jpg\")\n",
    "img = cv2.imread(image_file)\n",
    "cv2.imwrite(f\"./orig-image-{image_name}.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c35b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "print(image_name, image_ext)\n",
    "cv2.imwrite(f\"./grdd-cam-map-{image_name}.jpg\", superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59087a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.distributions as dist\n",
    "import torch.nn.functional as F\n",
    "\n",
    "image_file = image_files[2]\n",
    "img = Image.open(image_file)\n",
    "img = transform(img).unsqueeze(0)\n",
    "\n",
    "model = vgg19(weights=True)\n",
    "\n",
    "\n",
    "def ll_gaussian(y, mu, log_var):\n",
    "    sigma = torch.exp(0.5 * log_var)\n",
    "    return -0.5 * torch.log(2 * np.pi * sigma**2) - (1 / (2 * sigma**2)) * (y - mu) ** 2\n",
    "\n",
    "\n",
    "class VI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.q_mu = nn.Sequential(\n",
    "            nn.Linear(3 * 224 * 224, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3 * 224 * 224),\n",
    "        )\n",
    "        self.q_log_var = nn.Sequential(\n",
    "            nn.Linear(3 * 224 * 224, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 3 * 224 * 224),\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        # Define the minimum and maximum values for log_var\n",
    "        min_log_var = -10\n",
    "        max_log_var = 10\n",
    "\n",
    "        # Clip log_var to the specified range\n",
    "        clipped_log_var = torch.clamp(log_var, min_log_var, max_log_var)\n",
    "\n",
    "        # Compute sigma\n",
    "        sigma = torch.exp(0.5 * clipped_log_var) + 1e-5\n",
    "        # print(torch.sum(torch.isnan(sigma)))\n",
    "        # std can not be negative, thats why we use log variance\n",
    "        # sigma = torch.exp(0.5 * log_var) + 1e-5\n",
    "        eps = torch.randn_like(sigma)\n",
    "        return mu + sigma * eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu = self.q_mu(x)\n",
    "        log_var = self.q_log_var(x)\n",
    "        return self.reparameterize(mu, log_var), mu, log_var\n",
    "\n",
    "\n",
    "def elbo(x_pred, X, mu, log_var, model=model, predicted=pred_index.item()):\n",
    "    # HACK: use the CNN model predition as the input\n",
    "    model.eval()\n",
    "    input = x_pred.view(1, 3, 224, 224)\n",
    "    # Forward pass\n",
    "    outputs = model(input)\n",
    "    # print(torch.sum(torch.isnan(outputs)))\n",
    "    eps = 1e-8  # small constant\n",
    "\n",
    "    tmp = F.softmax(outputs, dim=1)[:, predicted] + eps\n",
    "    log_p_y = torch.log(tmp)\n",
    "    # HACK: use eps for variance, as we want\n",
    "    # Define the minimum and maximum values for log_var\n",
    "    min_log_var = -10\n",
    "    max_log_var = 10\n",
    "\n",
    "    # Clip log_var to the specified range\n",
    "    clipped_log_var = torch.clamp(log_var, min_log_var, max_log_var)\n",
    "\n",
    "    # Compute sigma\n",
    "    sigma = (clipped_log_var.exp() + 1e-8) ** 0.5\n",
    "\n",
    "    # likelihood of observing y given Variational mu and sigma\n",
    "    likelihood = dist.Normal(mu, sigma).log_prob(X)\n",
    "    # sigma = log_var.exp() ** 0.5\n",
    "    # # likelihood of observing y given Variational mu and sigma\n",
    "    # likelihood = dist.Normal(mu, sigma).log_prob(X)\n",
    "\n",
    "    # prior probability of x_pred\n",
    "    log_prior = dist.Normal(0, 1).log_prob(x_pred)\n",
    "\n",
    "    # variational probability of x_pred\n",
    "    log_p_q = dist.Normal(mu, sigma).log_prob(x_pred)\n",
    "\n",
    "    # by taking the mean we approximate the expectation\n",
    "    return (log_p_y + likelihood + log_prior - log_p_q).mean() + eps\n",
    "\n",
    "\n",
    "def det_loss(x_pred, X, mu, log_var, model=model, predicted=pred_index.item()):\n",
    "    return -elbo(x_pred, X, mu, log_var, model, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Training VI\"\"\"\n",
    "\n",
    "# NOTE: Train the VI model\n",
    "\n",
    "m = VI()\n",
    "optim = torch.optim.Adam(m.parameters(), lr=0.005)\n",
    "\n",
    "# Y = torch.rand(784).clone()\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs + 1):\n",
    "    X = img.view(3 * 224 * 224).clone()\n",
    "    optim.zero_grad()\n",
    "    x_pred, mu, log_var = m(X)\n",
    "    # Get the index of the max log-probability\n",
    "\n",
    "    loss = det_loss(x_pred, X, mu, log_var, model, pred_index.item())\n",
    "\n",
    "    # try view different digit\n",
    "    # loss = det_loss(x_pred, Y, mu, log_var, model, 3)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"epoch: {epoch}, loss: {loss}\")\n",
    "        # Y = mu.view(784).clone().detach()\n",
    "        # Y.requires_grad = True\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    X = img.view(3 * 224 * 224).clone()\n",
    "    x_pred, mu, log_var = m(X)\n",
    "    print(torch.abs(x_pred - X).mean())\n",
    "\n",
    "new_image = mu.view(1, 3, 224, 224)\n",
    "predicted = torch.argmax(F.softmax(model(new_image), dim=1))\n",
    "print(\n",
    "    f\"True y = {pred_index.item()}, the highest probability index: {predicted.max():.5f}\"\n",
    ")\n",
    "pred_prob = F.softmax(model(new_image), dim=1)[:, predicted]\n",
    "print(f\"New image full model prediction: {pred_prob.item()}\")\n",
    "new_image = new_image.permute(0, 2, 3, 1)\n",
    "plt.imshow(new_image.squeeze(0).detach().numpy())\n",
    "plt.title(\n",
    "    f\"Pred {pred_index.item()} Surrogate model with prediction: {pred_prob.item():.3f}\"\n",
    ")\n",
    "plt.savefig(f\"Surrogate_image-{image_name}.png\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(f\"variance: {log_var.exp().max()}\")\n",
    "highest_var = log_var.exp().max()\n",
    "k = 0.8\n",
    "high_var_index = np.where(log_var.view(3, 224, 224).exp() > highest_var * k)\n",
    "\n",
    "plt.imshow(X.view(3, 224, 224).permute(1, 2, 0).detach().numpy())\n",
    "# plt.scatter(high_var_index[1], high_var_index[0], s=10, c=\"red\")\n",
    "# Assume log_var is a tensor and you compute its exponential\n",
    "exp_values = log_var.view(3, 224, 224).exp()\n",
    "\n",
    "# Flatten the tensor to 1D for scatter plot\n",
    "exp_values_flatten = exp_values[high_var_index[0], high_var_index[1], high_var_index[2]]\n",
    "\n",
    "\n",
    "# Scatter plot with colors corresponding to exp_values\n",
    "plt.scatter(high_var_index[2], high_var_index[1], s=10, c=exp_values_flatten)\n",
    "\n",
    "# Add a colorbar to show the mapping from colors to values\n",
    "plt.title(f\"Pred {pred_index.item()} High Variance Index(> {k})\")\n",
    "plt.colorbar(label=\"exp(log_var)\")\n",
    "plt.savefig(f\"High_var_index-{image_name}.png\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        # get the pretrained DenseNet201 network\n",
    "        self.densenet = densenet201(pretrained=True)\n",
    "\n",
    "        # disect the network to access its last convolutional layer\n",
    "        self.features_conv = self.densenet.features\n",
    "\n",
    "        # add the average global pool\n",
    "        self.global_avg_pool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "\n",
    "        # get the classifier of the vgg19\n",
    "        self.classifier = self.densenet.classifier\n",
    "\n",
    "        # placeholder for the gradients\n",
    "        self.gradients = None\n",
    "\n",
    "    # hook for the gradients of the activations\n",
    "    def activations_hook(self, grad):\n",
    "        self.gradients = grad\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features_conv(x)\n",
    "\n",
    "        # register the hook\n",
    "        h = x.register_hook(self.activations_hook)\n",
    "\n",
    "        # don't forget the pooling\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view((1, 1920))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def get_activations_gradient(self):\n",
    "        return self.gradients\n",
    "\n",
    "    def get_activations(self, x):\n",
    "        return self.features_conv(x)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
